C++ 重载运算符在HotSpot VM中的应用:
内存分配与释放
在C++中可以通过new运算符和delete运算符进行内存分配与释放，由于C++没有GC托管技术，所以内存申请和释放通常集中到一个地方管理，才会有Metaspace或Arena这些相对复杂一些的内存管理机制。
在使用new关键字创建Klass或子类的实例时，都会调用Metaspace::allocate()函数从元数据区分配内存；在Klass类中，我们没有看到重载delete运算符，因为删除一个类并没有那么简单，需要借助GC来完成。

句柄(Handle)
句柄要间接操作实例，让GC能够集中扫描到栈中引用到的Java对象，句柄中重载了()、->和==运算符，大大简化了相关操作的简洁性，操作句柄就感觉和操作oop是一样的效果
// 将对象封装为句柄
Handle h1(obj1);
// 获取被封装的对象，会调用到operator()()函数，这个函数返回*_handleoop
obj2 = h1();
// 直接调用oop中定义的相关函数，会调用到operator->()函数，在这个函数中
// 获取_handle值后调用_handle->print()函数
h1->print();

C++指针和地址偏移在HotSpot VM中的应用:
operator new分配额外内存:
我们可以自己写个operator new函数对标准库函数进行重载，通常会根据类信息分配出需要的内存大小，但是我们也可以多分配一些内存，然后在多分配出来的内存上存储一些额外定义的信息(参考例子)
在HotSpot VM中也有这样的操作，例如Method，根据需要有两个可选择性的字段:
Method
native_function ptr
signature_handler ptr
当为native方法时，会为Method多开辟2个指针大小的存储空间

address* native_function_addr() const {
    assert(is_native(), "must be native");
    return (address*) (this+1);
}
address* signature_handler_addr() const {
    return native_function_addr() + 1;
}
注意这里的this+1，因为this的类型是Method实例，所以加1是增加一个Method对应的字节数，即获取Method对应内存区域的下一个字节的地址；
第二个native_function_addr() + 1，因为native_function_addr()返回的就是一个指针类型的数据，所以这里的加1是增加指针对应的字节数，64位下是8字节

offset_of宏的解析:
参考例子

C++ RAII在HotSpot VM中的重要应用:
RAII（Resource Acquisition Is Initialization），也称为“资源获取就是初始化”，是C++语言的一种管理资源、避免泄漏的惯用法。C++标准保证任何情况下，已构造的对象最终会销毁，即它的析构函数最终会被调用。
1、定义范围锁
class MutexLocker {
private:    pthread_mutex_t *_mtx;
public:
    MutexLocker(pthread_mutex_t *mtx) {
        if (mtx) {
            _mtx = mtx;
            pthread_mutex_lock(_mtx);
        }
    }
    ~MutexLocker() {
        if (_mtx)
            pthread_mutex_unlock(_mtx);
    }
};
我们还可以通过匿名块来进一步细化锁控制的范围。当进入作用域范围时，C++会自动调用MutexLocker的构造函数，当出了作用域范围时，会调用MutexLocker析构函数:
{
    // 整个匿名块都会在同步锁的保护下执行
    MutexLocker locker(&mutex);
    ...
}
2、管理内存资源
管理内存资源的一些类有HandleMark、ResourceMark等，HandleMark用来管理句柄，ResourceMark用来管理临时使用的内存。
由于Java类常量池中的字符串、还有一些公共字符串在HotSpot VM中都用Symbol实例来表示，如果想要看某个Klass实例表示的具体的类名称，我有时候会这样做：
{
    ResourceMark rm; //ResourceMark rm -> ResourceMark rm(Thread::current()) 记录匿名块开始时线程对应的内存ResourceArea，结束时进行恢复，避免内存泄漏
    Symbol *sym = _klass->name();
    const char *klassName = (sym->as_C_string()); //as_C_string会从ResourceArea申请内存
    ...
}

3、保存重要信息
JavaCallWrapper的作用: 1、管理内存资源，在第42篇-JNI引用的管理 2、记录Java调用栈的重要信息，退栈等操作非常依赖这些信息
{
    JavaCallWrapper link(...);
}
RAII技术被认为是C++中管理资源的最佳方法，进一步引申，使用RAII技术也可以实现安全、简洁的状态管理，编写出优雅的异常安全的代码。

C++的动态分派在HotSpot VM中的重要应用: (浅显)
void* vtable[1] = {  &Base::base_fun1  }; // 在Base class中，每个类只有一个虚表
const void**  vfptr = &vtable[0]; // 在Base object中，每个对象实例都只有一个虚表指针 (内存浪费)

jvm中使用KlassVtable来定义虚表

C++一种巧妙的内存管理方式:
class RelocationHolder {
private :
    enum {   _relocbuf_size = 5 };
    // 总共分配了5 * 8 = 40 字节大小的内存用来存储Relocation
    void* _relocbuf[ _relocbuf_size ];
public :
    Relocation* reloc() const {   return (Relocation*) &_relocbuf[0]; }
};

class Relocation {
public:
    // 通过new可以重复使用RelocationHolder的内存(如果RelocationHolder分配在栈上则会自动回收)
    void *operator new( size_t size,  const RelocationHolder &holder) {   return holder.reloc();  }
    // 子类按一定的规则将相应的数据写入CodeCache中
    virtual void pack_data_to() {}
};

DataRelocation : Relocation
CallRelocation : Relocation

关于x86的内存屏障:
内存屏障分为两层：编译器屏障和CPU屏障，前者只在编译期生效，目的是防止编译器生成乱序的内存访问指令；后者通过插入或修改特定的CPU指令，在运行时防止内存访问指令乱序执行。

编译器屏障:
asm volatile("": : :"memory")
它告诉编译器：这条指令（其实是空的）可能会读取/修改任何内存地址，那么编译器会变得保守起来，它会防止内存访问操作的乱序优化

x86 CPU屏障:
内存屏障可以分为两类：
本身是内存屏障，比如“lfence”，“sfence”和“mfence”汇编指令；
本身不是内存屏障，但是被lock指令前缀修饰，其组合成为一个内存屏障；(开销更小)

HotSpot VM中使用内存屏障：(x86和ia32架构)
x86和ia32架构只支持StoreLoad重排序(比较严格)，这个问题用lock前缀或mfence解决，不能靠组合sfence和lfence解决。
acquire语义防止它后面的读写操作重排序到acquire前面，所以LoadLoad和LoadStore组合后可满足要求；
release防止它前面的读写操作重排序到release后面，所以可由StoreStore和LoadStore组合后满足要求；
这样acquire(在上)和release(在下)就可以组合实现一个"栅栏"，禁止内部读写操作跑到外边，但是外边的读写操作仍然可以跑到“栅栏”内。

具体在实现时，acquire()函数读取了一个C++的volatile变量，而release()函数写入了一个C++的volatile变量。
这可能是微软从Visual Studio 2005开始就对C++ volatile关键字添加了同步语义，也就是对volatile变量的读操作具有acquire语义，对volatile变量的写操作具有release语义。

同时借助acquire与release语义可以实现互斥锁(mutex)，实际上，acquire的本意是acquire a lock，release的本意是release a lock，
因此，互斥锁能保证被锁住的区域内得到的数据不会是过期的数据，而且所有写入操作在release之前一定会写入内存。

关于CAS原子操作，说点别人没说的:
Atomic::cmpxchg{
    int mp = os::is_MP();
    __asm__ volatile (LOCK_IF_MP(%4) "cmpxchgl %1,(%3)"
    : "=a" (exchange_value)
    : "r" (exchange_value), "a" (compare_value), "r" (dest), "r" (mp)
    : "cc", "memory");
}
当操作系统为多核时，mp为true，此时会在cmpxchg指令之前加一个lock前缀。因为cmpxchg指令本身并不是原子的，但是加lock前缀后就会变为原子的。
cmpxhg的操作数可以是reg 和 reg，也可以是mem 和 reg，前者不需要lock，因为在同一个核上，寄存器只会有一套。只有mem 和 reg时才可能会需要lock，这个lock是对多核有效的。
xchg具有隐含的 LOCK语义，无需额外增加lock前缀
r表示将变量放入通用寄存器，而a表示rax寄存器(cmpxhg会比较rax和目标数，然后把源数写到目标数)
cc表示编译器汇编代码会导致CPU状态位的改变，也就是eflags
(__asm__相关内容参考gcc内嵌汇编)

历数Java虚拟机GC的种种缺点：
1、停顿：在垃圾收集时，垃圾收集周期要求所有的应用程序线程停顿，这样是为了避免在垃圾收集时，应用程序代码破坏垃圾收集线程所掌握的堆状态信息
2、占用更多的内存/内存利用率低：采用分代垃圾收集的GC不允许使用To Survivor区(占年轻代的1/10被浪费)；
老年代的空间利用率不是太高，总要有一部分担保空间来保证年轻代GC的顺利执行；
为了加快老年代的扫描速度，需要卡表和偏移表等数据结构进行辅助，这些都需要空间；
3、GC发生时间未知：
垃圾收集发生的时机没有确定性，也不是以固定的频率发生，这也会造成一些浮动垃圾，影响到空间利用率；
无法预知GC什么时候发生也会导致其它非预期的行为出现，如CMS触发FullGC时STW时间长，此时出现大量的Http请求则会导致大量超时
4、GC移动对象：
Java对象在GC后会被移动到其它地方，所以在GC期间不允许操作Java对象，引用这个Java对象的地址在GC后也需要更新
4.1、临界区
CriticalNative是一种特殊的JNI函数，整个函数都是一个阻止GC的临界区(禁止JVM进行垃圾回收的临界区)
4.2、堆外内存
许多的通信框架都会开辟一块堆外内存来提高效率(重复使用避免频繁申请内存)，因为操作系统把内存中的数据写入磁盘或网络时，要求数据所在的内存区域不能变动，但是GC会对内存进行整理，导致数据内存地址发生变化，所以只能先拷贝到堆外内存（不受GC影响），然后把这个地址发给操作系统